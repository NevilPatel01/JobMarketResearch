# ==============================================================================
# CANADA TECH JOB COMPASS - ENVIRONMENT VARIABLES
# ==============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to git (it's in .gitignore)

# ==============================================================================
# DATABASE CONFIGURATION (Supabase PostgreSQL)
# ==============================================================================
# Get these from: https://supabase.com/dashboard/project/YOUR_PROJECT/settings/database

SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_KEY=eyJhbGc...your-anon-key-here
SUPABASE_DB_URL=postgresql://postgres:[YOUR-PASSWORD]@db.xxxxx.supabase.co:5432/postgres

# Connection pool settings (optional, defaults are fine)
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10

# ==============================================================================
# API KEYS - DATA COLLECTION
# ==============================================================================

# RapidAPI - Get from: https://rapidapi.com/developer/applications
# Subscribe to: "Mantiks Canada Jobs API" or "FantasticJobs API"
RAPIDAPI_KEY=your-rapidapi-key-here
RAPIDAPI_HOST=mantiks-jobs-v1.p.rapidapi.com

# API Rate Limits (requests per month)
RAPIDAPI_MONTHLY_LIMIT=500

# ==============================================================================
# WEB SCRAPING CONFIGURATION
# ==============================================================================

# Job Bank Canada settings
JOBBANK_RATE_LIMIT_SECONDS=2.5
JOBBANK_MAX_PAGES=5
JOBBANK_REQUEST_TIMEOUT=30

# Selenium configuration
SELENIUM_HEADLESS=true
SELENIUM_WAIT_TIMEOUT=10
SELENIUM_IMPLICIT_WAIT=5

# User-Agent for respectful scraping
USER_AGENT=CanadaTechJobCompass/1.0 (Educational Project; contact@example.com)

# ==============================================================================
# DATA PROCESSING CONFIGURATION
# ==============================================================================

# Collection targets
TARGET_TOTAL_JOBS=2200
MIN_JOBS_PER_CITY=50
MIN_SOURCES=3

# Validation rules
MAX_JOB_AGE_DAYS=30
MIN_TITLE_LENGTH=3
MIN_DESCRIPTION_LENGTH=50
MIN_SALARY=30000
MAX_SALARY=250000

# Feature extraction
SPACY_MODEL=en_core_web_sm
MIN_SKILL_MENTIONS=3

# ==============================================================================
# FEATURE FLAGS
# ==============================================================================

ENABLE_JOBBANK=true
ENABLE_RAPIDAPI=true
ENABLE_RSS=true
ENABLE_SELENIUM=true
ENABLE_CACHING=true
ENABLE_ML_PREDICTIONS=false

# ==============================================================================
# CACHING CONFIGURATION
# ==============================================================================

CACHE_ENABLED=true
CACHE_DIR=cache
CACHE_TTL_HOURS=24

# ==============================================================================
# LOGGING CONFIGURATION
# ==============================================================================

LOG_LEVEL=INFO
LOG_FILE=logs/job_scraper.log
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5

# Log formats
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_DATE_FORMAT=%Y-%m-%d %H:%M:%S

# ==============================================================================
# RETRY & ERROR HANDLING
# ==============================================================================

MAX_RETRIES=3
RETRY_BACKOFF_MULTIPLIER=1
RETRY_MIN_WAIT=2
RETRY_MAX_WAIT=10

# ==============================================================================
# MONITORING & ALERTS
# ==============================================================================

# Alert thresholds
ALERT_MIN_JOBS=1800
ALERT_MAX_ERRORS=50
ALERT_MIN_SUCCESS_RATE=0.90

# Alert email (optional - for future notifications)
ALERT_EMAIL=your-email@example.com

# ==============================================================================
# CITIES & ROLES CONFIGURATION
# ==============================================================================

# Target cities (comma-separated)
TARGET_CITIES=Toronto,Saskatoon,Regina,Calgary,Edmonton,Winnipeg,Vancouver

# Target roles (comma-separated)
TARGET_ROLES=data analyst,it support,full stack developer,devops,web designer,business analyst,qa tester

# ==============================================================================
# POWER BI CONFIGURATION
# ==============================================================================

# Power BI connects directly to PostgreSQL via ODBC
# No export path needed - data is always live in database

# Power BI Service API (optional - for programmatic refresh)
POWERBI_CLIENT_ID=
POWERBI_CLIENT_SECRET=
POWERBI_WORKSPACE_ID=
POWERBI_DATASET_ID=

# Database materialized view refresh (for Power BI performance)
POWERBI_VIEW_NAME=mv_powerbi_export

# ==============================================================================
# SCHEDULER CONFIGURATION
# ==============================================================================

# Daily scrape time (24-hour format)
DAILY_SCRAPE_HOUR=2
DAILY_SCRAPE_MINUTE=0

# Pipeline stages to run
RUN_COLLECTION=true
RUN_VALIDATION=true
RUN_DEDUPLICATION=true
RUN_FEATURE_EXTRACTION=true
RUN_STORAGE=true
RUN_ANALYSIS=true

# ==============================================================================
# DEVELOPMENT/PRODUCTION MODE
# ==============================================================================

ENV=development
DEBUG=false

# Set to 'true' for testing with small data samples
TEST_MODE=false
TEST_MODE_MAX_JOBS=50

# ==============================================================================
# GITHUB ACTIONS (CI/CD)
# ==============================================================================
# These are set automatically by GitHub Actions, but you can override locally

CI=false
GITHUB_WORKFLOW=
GITHUB_RUN_NUMBER=

# ==============================================================================
# NOTES
# ==============================================================================
# 1. Required for basic operation:
#    - SUPABASE_URL, SUPABASE_KEY, SUPABASE_DB_URL
#    - RAPIDAPI_KEY (or disable with ENABLE_RAPIDAPI=false)
#
# 2. Optional (scraping will work without):
#    - ALERT_EMAIL, POWERBI_* variables
#
# 3. For local development:
#    - Set ENV=development
#    - Set TEST_MODE=true for faster testing
#
# 4. For production:
#    - Set ENV=production
#    - Set DEBUG=false
#    - Configure GitHub Secrets for CI/CD
#
# 5. Security:
#    - Never commit this file with real values to git
#    - Use strong passwords for database
#    - Rotate API keys regularly
